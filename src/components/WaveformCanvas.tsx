import { useRef, useEffect, useCallback, useState } from 'react'
import styles from './WaveformCanvas.module.css'

interface WaveformCanvasProps {
  recordingData: Float32Array | null
  isRecording?: boolean
  progress?: number // 0-1ã®éŒ²éŸ³é€²æ—
}

export function WaveformCanvas({ recordingData, isRecording = false, progress = 1 }: WaveformCanvasProps) {
  const canvasRef = useRef<HTMLCanvasElement>(null)
  const audioContextRef = useRef<AudioContext | null>(null)
  const sourceNodeRef = useRef<AudioBufferSourceNode | null>(null)
  const [isPlaying, setIsPlaying] = useState(false)

  const drawEmptyCanvas = useCallback((canvas: HTMLCanvasElement, ctx: CanvasRenderingContext2D) => {
    ctx.fillStyle = '#fafafa'
    ctx.fillRect(0, 0, canvas.width, canvas.height)

    // ä¸­å¿ƒç·šã‚’æç”»
    ctx.strokeStyle = '#ddd'
    ctx.lineWidth = 1
    ctx.beginPath()
    ctx.moveTo(0, canvas.height / 2)
    ctx.lineTo(canvas.width, canvas.height / 2)
    ctx.stroke()

    // ãƒ†ã‚­ã‚¹ãƒˆã‚’è¡¨ç¤º
    ctx.fillStyle = '#999'
    ctx.font = '16px sans-serif'
    ctx.textAlign = 'center'
    ctx.fillText(
      'éŒ²éŸ³ãƒœã‚¿ãƒ³ã‚’æŠ¼ã™ã¨éŸ³å£°æ³¢å½¢ãŒè¡¨ç¤ºã•ã‚Œã¾ã™',
      canvas.width / 2,
      canvas.height / 2 - 10
    )
  }, [])

  const drawWaveform = useCallback((canvas: HTMLCanvasElement, ctx: CanvasRenderingContext2D, data: Float32Array, currentProgress: number) => {
    // ã‚­ãƒ£ãƒ³ãƒã‚¹ã‚’ã‚¯ãƒªã‚¢
    ctx.fillStyle = '#fafafa'
    ctx.fillRect(0, 0, canvas.width, canvas.height)

    // ä¸­å¿ƒç·šã‚’æç”»ï¼ˆèƒŒæ™¯ã¨ã—ã¦å…ˆã«æç”»ï¼‰
    ctx.strokeStyle = '#ddd'
    ctx.lineWidth = 1
    ctx.beginPath()
    ctx.moveTo(0, canvas.height / 2)
    ctx.lineTo(canvas.width, canvas.height / 2)
    ctx.stroke()

    // æ³¢å½¢ã‚’æç”»
    // éŒ²éŸ³ä¸­ã¯é€²æ—ã«å¿œã˜ãŸå¹…ã§æç”»ã€å®Œäº†å¾Œã¯å…¨ä½“ã‚’ä½¿ç”¨
    const drawWidth = canvas.width * currentProgress
    const sliceWidth = drawWidth / data.length
    
    ctx.strokeStyle = '#2196F3'
    ctx.lineWidth = 2
    ctx.beginPath()

    let x = 0

    for (let i = 0; i < data.length; i++) {
      const y = ((data[i] + 1) * canvas.height) / 2

      if (i === 0) {
        ctx.moveTo(x, y)
      } else {
        ctx.lineTo(x, y)
      }

      x += sliceWidth
    }

    ctx.stroke()
  }, [])

  // æ³¢å½¢ã‚’å†ç”Ÿã™ã‚‹é–¢æ•°
  const playWaveform = useCallback(async () => {
    if (!recordingData || recordingData.length === 0) {
      console.log('å†ç”Ÿãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“')
      return
    }

    console.log('å†ç”Ÿé–‹å§‹:', recordingData.length, 'ã‚µãƒ³ãƒ—ãƒ«')

    // æ—¢ã«å†ç”Ÿä¸­ãªã‚‰åœæ­¢
    if (sourceNodeRef.current) {
      try {
        sourceNodeRef.current.stop()
      } catch (e) {
        // already stopped
      }
      sourceNodeRef.current = null
    }

    try {
      // AudioContextã‚’ä½œæˆï¼ˆã¾ãŸã¯å†åˆ©ç”¨ï¼‰
      if (!audioContextRef.current || audioContextRef.current.state === 'closed') {
        audioContextRef.current = new (window.AudioContext || (window as typeof window & { webkitAudioContext: typeof AudioContext }).webkitAudioContext)()
      }

      const audioContext = audioContextRef.current

      // AudioContextãŒsuspendedãªã‚‰å†é–‹
      if (audioContext.state === 'suspended') {
        await audioContext.resume()
      }

      // å®Ÿéš›ã®ã‚µãƒ³ãƒ—ãƒ«ãƒ¬ãƒ¼ãƒˆã‚’ä½¿ç”¨
      const sampleRate = audioContext.sampleRate
      console.log('ã‚µãƒ³ãƒ—ãƒ«ãƒ¬ãƒ¼ãƒˆ:', sampleRate)

      // AudioBufferã‚’ä½œæˆ
      const audioBuffer = audioContext.createBuffer(1, recordingData.length, sampleRate)
      const channelData = audioBuffer.getChannelData(0)
      
      // æ³¢å½¢ãƒ‡ãƒ¼ã‚¿ã‚’ã‚³ãƒ”ãƒ¼ï¼ˆéŸ³é‡ã‚’èª¿æ•´ï¼‰
      const maxAmplitude = Math.max(...Array.from(recordingData).map(Math.abs))
      const gain = maxAmplitude > 0 ? 0.8 / maxAmplitude : 1
      console.log('æœ€å¤§æŒ¯å¹…:', maxAmplitude, 'ã‚²ã‚¤ãƒ³:', gain)
      
      for (let i = 0; i < recordingData.length; i++) {
        channelData[i] = recordingData[i] * gain
      }

      // AudioBufferSourceNodeã‚’ä½œæˆã—ã¦å†ç”Ÿ
      const sourceNode = audioContext.createBufferSource()
      sourceNode.buffer = audioBuffer
      sourceNode.connect(audioContext.destination)
      
      sourceNode.onended = () => {
        console.log('å†ç”Ÿçµ‚äº†')
        setIsPlaying(false)
        sourceNodeRef.current = null
      }

      sourceNodeRef.current = sourceNode
      setIsPlaying(true)
      sourceNode.start(0)
      console.log('å†ç”Ÿä¸­...')
    } catch (error) {
      console.error('å†ç”Ÿã‚¨ãƒ©ãƒ¼:', error)
      setIsPlaying(false)
    }
  }, [recordingData])

  // å†ç”Ÿåœæ­¢
  const stopWaveform = useCallback(() => {
    if (sourceNodeRef.current) {
      try {
        sourceNodeRef.current.stop()
      } catch (e) {
        // already stopped
      }
      sourceNodeRef.current = null
      setIsPlaying(false)
    }
  }, [])

  // ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
  useEffect(() => {
    return () => {
      if (sourceNodeRef.current) {
        sourceNodeRef.current.stop()
      }
      if (audioContextRef.current) {
        audioContextRef.current.close()
      }
    }
  }, [])

  const setupCanvas = useCallback(() => {
    const canvas = canvasRef.current
    if (!canvas) return

    const ctx = canvas.getContext('2d')
    if (!ctx) return

    canvas.width = canvas.offsetWidth
    canvas.height = canvas.offsetHeight

    if (recordingData && recordingData.length > 0) {
      // éŒ²éŸ³ä¸­ã¯é€²æ—ã‚’ä½¿ç”¨ã€å®Œäº†å¾Œã¯1ï¼ˆå…¨ä½“è¡¨ç¤ºï¼‰
      const currentProgress = isRecording ? progress : 1
      drawWaveform(canvas, ctx, recordingData, currentProgress)
    } else {
      drawEmptyCanvas(canvas, ctx)
    }
  }, [recordingData, isRecording, progress, drawEmptyCanvas, drawWaveform])

  useEffect(() => {
    setupCanvas()
  }, [setupCanvas])

  useEffect(() => {
    const handleResize = () => {
      setupCanvas()
    }

    window.addEventListener('resize', handleResize)
    return () => {
      window.removeEventListener('resize', handleResize)
    }
  }, [setupCanvas])

  return (
    <div className={styles.canvasContainer}>
      <div className={styles.canvasHeader}>
        <h3 style={{ margin: 0, color: '#2196F3' }}>ğŸ™ï¸ éŒ²éŸ³ãƒ‡ãƒ¼ã‚¿</h3>
        {recordingData && recordingData.length > 0 && !isRecording && (
          <button 
            onClick={isPlaying ? stopWaveform : playWaveform}
            className={styles.playButton}
            style={{ backgroundColor: '#2196F3' }}
            title={isPlaying ? 'åœæ­¢' : 'å†ç”Ÿ'}
          >
            {isPlaying ? 'â¹ï¸ åœæ­¢' : 'â–¶ï¸ å†ç”Ÿ'}
          </button>
        )}
      </div>
      <canvas ref={canvasRef} className={styles.waveformCanvas} />
    </div>
  )
}
